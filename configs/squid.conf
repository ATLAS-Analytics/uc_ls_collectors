 input {
  http {
    host => "0.0.0.0"
    port => "80"
  }
}

filter {
  json {
    source => "message"
    remove_field => [ "message" ]
  }
  # if [token] != [ "sqKHBKJB45n" ] {
  #   drop {}
  # }
  mutate {
    remove_field => [ "headers", "token", "host" ]
  }
  split {
    field => "data"
  }
    mutate {
     rename => { "[data][experiment]" => "[experiment]" } 
     rename => { "[data][site]" => "[site]" } 
     rename => { "[data][squid]" => "[squid]" }  
     rename => { "[data][HTTP reqs]" => "[HTTP requests]" }  
     rename => { "[data][HTTP fetches]" => "[HTTP fetches]" }  
     rename => { "[data][Fetches]" => "[Data fetched]" }  
     rename => { "[data][Total]" => "[Data delivered]" }    
     rename => { "[data][Used]" => "[Used file descriptors]" }  
     rename => { "[data][Obj num]" => "[Cached objects]" }    
     rename => { "[data][Available]" => "[Available file descriptors]" }  
     rename => { "[data][Cpu time]" => "[CPU time]" }  
     rename => { "[data][timestamp]" => "[timestamp]" }  
     remove_field => ["data"]
  }
}

output {

  #  stdout {
  #    codec => rubydebug
  #  }
  
  if "_jsonparsefailure" in [tags] {
    file {
      path => "/var/log/logstash/json_parse_failure.txt"
    }
  }
  else if "_rubyexception" in [tags] {
    file {
      path => "/var/log/logstash/ruby_exception.json"
    }
  }  

  elasticsearch {
    hosts => "atlas-kibana.mwt2.org"
    ssl => true
    index => 'squids-%{+YYYY-MM}'
    user => "uc_logstash_indexer"
    password => "${LOGSTASH_PWD}"
  }

}